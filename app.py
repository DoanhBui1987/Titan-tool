import streamlit as st
import google.generativeai as genai
from PIL import Image

# --- 1. C·∫§U H√åNH GIAO DI·ªÜN ---
st.set_page_config(page_title="TITAN VISION v4.0", page_icon="üëÅÔ∏è", layout="wide")

# CSS l√†m ƒë·∫πp n√∫t b·∫•m
st.markdown("""
<style>
    .stButton>button {
        width: 100%;
        background: linear-gradient(90deg, #FF4B4B 0%, #FF914D 100%);
        color: white;
        font-weight: bold;
        border: none;
        height: 3em;
    }
</style>
""", unsafe_allow_html=True)

st.title("üëÅÔ∏è TITAN VISION ENGINE v4.0")
st.caption("Strategic Partner Edition - Auto Detect Model")

# --- 2. SIDEBAR C·∫§U H√åNH ---
with st.sidebar:
    st.header("‚öôÔ∏è Trung t√¢m ƒëi·ªÅu khi·ªÉn")
    
    # X·ª≠ l√Ω API Key
    if 'GOOGLE_API_KEY' in st.secrets:
        api_key = st.secrets['GOOGLE_API_KEY']
        st.success("‚úÖ ƒê√£ n·∫°p API Key b·∫£o m·∫≠t")
    else:
        api_key = st.text_input("üîë Google API Key", type="password")
        st.caption("Ch∆∞a c√≥ key? V√†o Google AI Studio l·∫•y nh√©.")
    
    mode = st.radio("Ch·∫ø ƒë·ªô:", ["Auto-Router", "Vision Analysis", "Code Audit"])
    
    st.divider()
    
    # --- DEBUG INFO (ƒê·ªÇ SOI L·ªñI) ---
    # Ph·∫ßn n√†y c·ª±c quan tr·ªçng ƒë·ªÉ bi·∫øt t√†i kho·∫£n b·∫°n c√≥ model g√¨
    available_models = []
    with st.expander("üõ†Ô∏è Debug th√¥ng tin Model", expanded=True):
        if api_key:
            try:
                genai.configure(api_key=api_key)
                # L·∫•y danh s√°ch model th·ª±c t·∫ø
                available_models = [m.name for m in genai.list_models()]
                st.write("Model t√¨m th·∫•y:", available_models)
            except Exception as e:
                st.error(f"L·ªói k·∫øt n·ªëi: {e}")
        else:
            st.warning("Nh·∫≠p Key ƒë·ªÉ xem model.")

# --- 3. LOGIC CH·ªåN MODEL TH√îNG MINH ---
def get_best_model(models_list):
    """Ch·ªçn model d·ª±a tr√™n danh s√°ch th·ª±c t·∫ø"""
    try:
        # ∆Øu ti√™n Flash (Nhanh, R·∫ª, Vision ngon)
        if 'models/gemini-1.5-flash' in models_list:
            return genai.GenerativeModel('gemini-1.5-flash')
        
        # N·∫øu kh√¥ng c√≥ Flash, t√¨m Pro Vision (B·∫£n c≈© nh∆∞ng c√≥ m·∫Øt)
        elif 'models/gemini-pro-vision' in models_list:
            return genai.GenerativeModel('gemini-pro-vision')
            
        # ƒê∆∞·ªùng c√πng th√¨ d√πng Gemini Pro (Ch·ªâ text)
        elif 'models/gemini-pro' in models_list:
            return genai.GenerativeModel('gemini-pro')
            
        # N·∫øu danh s√°ch r·ªóng ho·∫∑c l·∫°, th·ª≠ g·ªçi Flash m·∫∑c ƒë·ªãnh
        else:
            return genai.GenerativeModel('gemini-1.5-flash')
            
    except Exception as e:
        return None

TITAN_INSTRUCTION = """
ROLE: B·∫°n l√† TITAN v4.0. Nhi·ªám v·ª•: Ph√¢n t√≠ch Input v√† ƒë∆∞a ra gi·∫£i ph√°p "Production-Ready".
OUTPUT: Markdown format. Chia l√†m 3 ph·∫ßn: The Verdict, Deep Dive, Action Plan.
"""

# --- 4. GIAO DI·ªÜN CH√çNH ---
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("üì• D·ªØ li·ªáu ƒë·∫ßu v√†o")
    txt_input = st.text_area("Nh·∫≠p √Ω t∆∞·ªüng / Code / C√¢u h·ªèi:", height=250, placeholder="V√≠ d·ª•: Ph√¢n t√≠ch b·ª©c ·∫£nh n√†y...")
    
    uploaded_file = st.file_uploader("T·∫£i ·∫£nh ph√¢n t√≠ch (JPG/PNG):", type=["jpg", "png", "jpeg"])
    img_data = None
    if uploaded_file:
        img_data = Image.open(uploaded_file)
        st.image(img_data, caption="·∫¢nh Preview", use_container_width=True)
    
    btn_run = st.button("üöÄ K√çCH HO·∫†T TITAN")

with col2:
    st.subheader("üíé K·∫øt qu·∫£ ph√¢n t√≠ch")
    
    if btn_run:
        if not api_key:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p API Key tr∆∞·ªõc khi ch·∫°y!")
        else:
            with st.spinner("üì° TITAN ƒëang k·∫øt n·ªëi v·ªá tinh..."):
                try:
                    genai.configure(api_key=api_key)
                    
                    # G·ªçi h√†m ch·ªçn model th√¥ng minh d·ª±a tr√™n list ƒë√£ qu√©t
                    model = get_best_model(available_models)
                    
                    if model is None:
                        st.error("üî• L·ªói kh·ªüi t·∫°o Model.")
                    else:
                        # Chu·∫©n b·ªã Prompt
                        req = [f"MODE: {mode}\nINPUT: {txt_input}"]
                        if img_data:
                            # Ki·ªÉm tra n·∫øu model ch·ªâ h·ªó tr·ª£ text (gemini-pro th∆∞·ªùng)
                            if 'gemini-pro' in model.model_name and 'vision' not in model.model_name:
                                st.warning(f"‚ö†Ô∏è Model '{model.model_name}' kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh. ƒêang ch·∫°y ch·∫ø ƒë·ªô Text.")
                            else:
                                req.append(img_data)
                                req[0] += "\n(C√ì ·∫¢NH ƒê√çNH K√àM)"
                        
                        # K·∫πp instruction v√†o prompt ƒë·ªÉ an to√†n cho m·ªçi model
                        req[0] = TITAN_INSTRUCTION + "\n\n" + req[0]

                        # B·∫Øn API
                        response = model.generate_content(req)
                        
                        # Hi·ªán k·∫øt qu·∫£
                        st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω xong b·∫±ng model: {model.model_name}")
                        st.markdown(response.text)
                        
                        # N√∫t t·∫£i v·ªÅ
                        st.download_button("üíæ T·∫£i b√°o c√°o (.md)", response.text, "Titan_Report.md")
                        
                except Exception as e:
                    st.error(f"üî• L·ªñI H·ªÜ TH·ªêNG: {str(e)}")
