import streamlit as st
import google.generativeai as genai
from PIL import Image
import sys

# ==========================================
# 1. C·∫§U H√åNH & KI·ªÇM TRA M√îI TR∆Ø·ªúNG
# ==========================================
st.set_page_config(page_title="TITAN IMMORTAL", page_icon="üõ°Ô∏è", layout="wide")

st.markdown("""
<style>
    .stButton>button {background: #00C853; color: white; font-weight: bold;}
    .reportview-container {background: #0E1117;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. LOGIC "B·∫§T T·ª¨" (T·ª∞ ƒê·ªòNG D√í T√åM MODEL)
# ==========================================
def get_working_model_response(api_key, prompt, image):
    # C·∫•u h√¨nh API
    genai.configure(api_key=api_key)
    
    # DANH S√ÅCH C√ÅC MODEL S·∫º TH·ª¨ L·∫¶N L∆Ø·ª¢T
    # Google ƒë·ªïi t√™n li√™n t·ª•c, n√™n ta c·ª© th·ª≠ h·∫øt list n√†y
    model_list = [
        "gemini-1.5-flash",          # ∆Øu ti√™n 1: Nhanh, R·∫ª
        "gemini-1.5-flash-latest",   # ∆Øu ti√™n 2: B·∫£n m·ªõi nh·∫•t
        "gemini-1.5-pro",            # ∆Øu ti√™n 3: Th√¥ng minh h∆°n nh∆∞ng ch·∫≠m
        "gemini-1.5-pro-latest",     # ∆Øu ti√™n 4
    ]
    
    log_report = [] # Ghi l·∫°i l·ªãch s·ª≠ th·ª≠
    
    for model_name in model_list:
        try:
            # T·∫°o model
            model = genai.GenerativeModel(model_name)
            
            # Chu·∫©n b·ªã n·ªôi dung
            content = [prompt]
            if image:
                content.append(image)
                
            # G·ªåI API
            response = model.generate_content(content)
            
            # N·∫øu ch·∫°y ƒë·∫øn ƒë√¢y t·ª©c l√† th√†nh c√¥ng!
            return {
                "success": True, 
                "model_used": model_name, 
                "text": response.text,
                "log": log_report
            }
            
        except Exception as e:
            # N·∫øu l·ªói, ghi l·∫°i v√† th·ª≠ th·∫±ng ti·∫øp theo
            error_msg = str(e)
            log_report.append(f"‚ùå {model_name}: Th·∫•t b·∫°i ({error_msg})")
            continue 

    # N·∫øu th·ª≠ h·∫øt s·∫°ch list m√† v·∫´n l·ªói
    return {
        "success": False, 
        "text": "T·∫§T C·∫¢ MODEL ƒê·ªÄU TH·∫§T B·∫†I. Vui l√≤ng ki·ªÉm tra API Key ho·∫∑c File requirements.txt",
        "log": log_report
    }

# ==========================================
# 3. GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG
# ==========================================
with st.sidebar:
    st.header("üõ°Ô∏è C·∫§U H√åNH")
    
    # Ki·ªÉm tra version th∆∞ vi·ªán
    lib_ver = genai.__version__
    if lib_ver < "0.7.0":
        st.error(f"‚ö†Ô∏è TH∆Ø VI·ªÜN C≈® QU√Å ({lib_ver})!")
        st.warning("B·∫°n c·∫ßn t·∫°o file requirements.txt v·ªõi n·ªôi dung: google-generativeai>=0.7.2")
    else:
        st.success(f"‚úÖ Th∆∞ vi·ªán ·ªïn: v{lib_ver}")

    # Nh·∫≠p Key
    if 'GOOGLE_API_KEY' in st.secrets:
        api_key = st.secrets['GOOGLE_API_KEY']
        st.success("ƒê√£ nh·∫≠n Key ·∫©n")
    else:
        api_key = st.text_input("Nh·∫≠p API Key:", type="password")

st.title("üõ°Ô∏è TITAN IMMORTAL v7.0")
st.caption("C∆° ch·∫ø t·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi Model khi Google thay ƒë·ªïi.")

col1, col2 = st.columns([1, 1])

with col1:
    user_prompt = st.text_area("N·ªôi dung:", height=150, value="M√¥ t·∫£ b·ª©c ·∫£nh n√†y th·∫≠t chi ti·∫øt.")
    uploaded_file = st.file_uploader("·∫¢nh:", type=["jpg", "png", "jpeg"])
    
    image_data = None
    if uploaded_file:
        image_data = Image.open(uploaded_file)
        st.image(image_data, caption="Input", width=300)

    btn_run = st.button("üöÄ K√çCH HO·∫†T")

with col2:
    if btn_run:
        if not api_key:
            st.error("Ch∆∞a c√≥ API Key!")
        else:
            with st.spinner("ü§ñ Titan ƒëang th·ª≠ k·∫øt n·ªëi c√°c v·ªá tinh..."):
                # G·ªçi h√†m b·∫•t t·ª≠
                result = get_working_model_response(api_key, user_prompt, image_data)
                
                if result["success"]:
                    st.success(f"‚úÖ Th√†nh c√¥ng v·ªõi model: **{result['model_used']}**")
                    st.markdown(result["text"])
                    with st.expander("Xem nh·∫≠t k√Ω k·∫øt n·ªëi"):
                        st.write(result["log"])
                else:
                    st.error("üî• H·ªÜ TH·ªêNG S·ª§P ƒê·ªî!")
                    st.write(result["text"])
                    with st.expander("Chi ti·∫øt l·ªói (G·ª≠i c√°i n√†y cho k·ªπ thu·∫≠t)"):
                        st.write(result["log"])
