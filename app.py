import streamlit as st
import requests
import json
import base64
from PIL import Image
import io

# ==============================================================================
# MODULE 1: C·∫§U H√åNH & GIAO DI·ªÜN H·ªÜ TH·ªêNG
# ==============================================================================
st.set_page_config(
    page_title="TITAN VISION X (Final Stable)",
    page_icon="üßø",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS cho giao di·ªán chuy√™n nghi·ªáp h∆°n
st.markdown("""
<style>
    .stButton>button {
        background: linear-gradient(90deg, #4b6cb7 0%, #182848 100%);
        color: white;
        border: none;
        height: 3.5em;
        font-weight: bold;
        border-radius: 8px;
        font-size: 16px;
    }
    .stButton>button:hover {
        opacity: 0.9;
        transform: scale(1.01);
    }
    .stTextArea textarea {
        background-color: #f0f2f6;
        color: #000;
        border-radius: 8px;
    }
    [data-testid="stSidebar"] {
        background-color: #f8f9fa;
    }
    h1, h2, h3 { color: #182848; }
</style>
""", unsafe_allow_html=True)

# ==============================================================================
# MODULE 2: C√ÅC H√ÄM X·ª¨ L√ù LOGIC (BACKEND)
# ==============================================================================

def encode_image(image_file):
    """Chuy·ªÉn ƒë·ªïi file ·∫£nh sang Base64 v√† x√°c ƒë·ªãnh Mime Type"""
    if image_file is not None:
        try:
            # L·∫•y mime type th·ª±c t·∫ø (quan tr·ªçng ƒë·ªÉ fix l·ªói m√π ·∫£nh)
            mime_type = image_file.type
            
            # ƒê·ªçc file v√† chuy·ªÉn sang bytes
            image_instance = Image.open(image_file)
            img_byte_arr = io.BytesIO()
            # L∆∞u l·∫°i v√†o buffer ƒë·ªÉ l·∫•y bytes, gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng g·ªëc
            image_instance.save(img_byte_arr, format=image_instance.format)
            encoded_string = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
            
            return {"mime_type": mime_type, "data": encoded_string}
        except Exception as e:
            st.error(f"L·ªói x·ª≠ l√Ω ·∫£nh: {e}")
            return None
    return None

def read_text_file(txt_file):
    """ƒê·ªçc n·ªôi dung file text/code ƒë·ªÉ l√†m context"""
    if txt_file is not None:
        try:
            stringio = io.StringIO(txt_file.getvalue().decode("utf-8"))
            return stringio.read()
        except Exception as e:
            st.warning(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file {txt_file.name}: {e}")
            return ""
    return ""

def call_gemini_rest_api(api_key, model, prompt, image_data=None, system_instruction=None):
    """H√†m l√µi g·ªçi Google REST API (Kh√¥ng d√πng th∆∞ vi·ªán trung gian)"""
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
    headers = {'Content-Type': 'application/json'}

    # 1. X√¢y d·ª±ng System Prompt (N·∫øu c√≥)
    final_prompt = prompt
    if system_instruction:
        final_prompt = f"{system_instruction}\n\n---\nUSER REQUEST:\n{prompt}"

    # 2. X√¢y d·ª±ng Content Parts
    parts = []
    
    # N·∫øu c√≥ ·∫£nh, ƒë∆∞a ·∫£nh v√†o tr∆∞·ªõc
    if image_data:
        parts.append({
            "inline_data": {
                "mime_type": image_data['mime_type'],
                "data": image_data['data']
            }
        })
    
    # ƒê∆∞a text v√†o sau
    parts.append({"text": final_prompt})

    # 3. ƒê√≥ng g√≥i Payload
    payload = {
        "contents": [{
            "parts": parts
        }]
    }

    # 4. G·ª≠i Request
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        
        if response.status_code == 200:
            return {
                "success": True, 
                "text": response.json()['candidates'][0]['content']['parts'][0]['text']
            }
        else:
            return {
                "success": False, 
                "error_code": response.status_code,
                "detail": response.text
            }
    except Exception as e:
        return {"success": False, "detail": str(e)}

# ==============================================================================
# MODULE 3: SIDEBAR & C·∫§U H√åNH (CONTROLLER)
# ==============================================================================

with st.sidebar:
    st.title("‚öôÔ∏è TRUNG T√ÇM ƒêI·ªÄU KHI·ªÇN")
    
    # 1. Qu·∫£n l√Ω API Key
    st.subheader("1. API Key")
    if 'GOOGLE_API_KEY' in st.secrets:
        api_key = st.secrets['GOOGLE_API_KEY']
        st.success("‚úÖ ƒê√£ n·∫°p Key b·∫£o m·∫≠t t·ª´ h·ªá th·ªëng")
    else:
        api_key = st.text_input("Nh·∫≠p Google API Key:", type="password", help="L·∫•y t·∫°i aistudio.google.com")

    st.divider()

    # 2. Ch·ªçn Model (Model Hunter Logic)
    st.subheader("2. Ch·ªçn B·ªô N√£o AI")
    # Danh s√°ch d·ª± ph√≤ng n·∫øu kh√¥ng fetch ƒë∆∞·ª£c
    model_options = ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-2.0-flash-exp"]
    
    # N√∫t l√†m m·ªõi danh s√°ch
    if st.button("üîÑ Qu√©t Model kh·∫£ d·ª•ng"):
        if api_key:
            try:
                resp = requests.get(f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}")
                if resp.status_code == 200:
                    data = resp.json()
                    fetched_models = []
                    for m in data.get('models', []):
                        if "generateContent" in m.get('supportedGenerationMethods', []):
                            fetched_models.append(m['name'].replace("models/", ""))
                    # ∆Øu ti√™n ƒë∆∞a 2.0 l√™n ƒë·∫ßu
                    fetched_models.sort(key=lambda x: "2.0" in x, reverse=True)
                    model_options = fetched_models
                    st.toast(f"T√¨m th·∫•y {len(fetched_models)} models!", icon="üéâ")
            except:
                st.warning("Kh√¥ng qu√©t ƒë∆∞·ª£c, d√πng danh s√°ch m·∫∑c ƒë·ªãnh.")
    
    selected_model = st.selectbox("Model ƒëang d√πng:", model_options)

    st.divider()

    # 3. Ch·∫ø ƒë·ªô (Personas - Kh√¥i ph·ª•c t√≠nh nƒÉng ƒë√£ m·∫•t)
    st.subheader("3. Ch·∫ø ƒë·ªô ho·∫°t ƒë·ªông")
    mode = st.radio(
        "Ch·ªçn vai tr√≤:",
        ["Tr·ª£ l√Ω ƒêa nƒÉng", "Chuy√™n gia Code (Audit)", "S√°ng t·∫°o (Marketing)", "Ph√¢n t√≠ch D·ªØ li·ªáu"]
    )
    
    # Mapping system instruction
    system_prompts = {
        "Tr·ª£ l√Ω ƒêa nƒÉng": "B·∫°n l√† tr·ª£ l√Ω AI h·ªØu √≠ch, tr·∫£ l·ªùi ng·∫Øn g·ªçn, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.",
        "Chuy√™n gia Code (Audit)": "B·∫°n l√† Senior Software Engineer. Nhi·ªám v·ª•: Review code, t√¨m bug, gi·∫£i th√≠ch logic, t·ªëi ∆∞u h√≥a v√† vi·∫øt docstring. Ch·ªâ d√πng Markdown cho code.",
        "S√°ng t·∫°o (Marketing)": "B·∫°n l√† Copywriter chuy√™n nghi·ªáp. Gi·ªçng vƒÉn: Thu h√∫t, viral, c·∫£m x√∫c. D√πng emoji h·ª£p l√Ω.",
        "Ph√¢n t√≠ch D·ªØ li·ªáu": "B·∫°n l√† Data Analyst. Ph√¢n t√≠ch d·ªØ li·ªáu/h√¨nh ·∫£nh ƒë·∫ßu v√†o, t√¨m ra insight, xu h∆∞·ªõng v√† tr√¨nh b√†y d∆∞·ªõi d·∫°ng bullet point r√µ r√†ng."
    }
    current_instruction = system_prompts[mode]

# ==============================================================================
# MODULE 4: GIAO DI·ªÜN CH√çNH (VIEW)
# ==============================================================================

st.title("üßø TITAN VISION X")
st.caption(f"Powered by **{selected_model}** | Mode: **{mode}**")

col_left, col_right = st.columns([1, 1])

# --- INPUT AREA ---
with col_left:
    st.subheader("üì• D·ªØ li·ªáu ƒë·∫ßu v√†o")
    
    # Tab ch·ªçn lo·∫°i input
    tab1, tab2 = st.tabs(["üí¨ VƒÉn b·∫£n & ·∫¢nh", "üìÑ T·ªáp ƒë√≠nh k√®m (RAG Lite)"])
    
    with tab1:
        user_text = st.text_area("Nh·∫≠p c√¢u l·ªánh/Prompt:", height=150, placeholder="V√≠ d·ª•: Gi·∫£i th√≠ch ƒëo·∫°n code n√†y, ho·∫∑c M√¥ t·∫£ b·ª©c ·∫£nh...")
        uploaded_img = st.file_uploader("T·∫£i ·∫£nh (Vision):", type=["png", "jpg", "jpeg", "webp", "heic"])
        
        # Preview ·∫£nh
        processed_img_data = None
        if uploaded_img:
            st.image(uploaded_img, caption="·∫¢nh Input", use_container_width=True)
            processed_img_data = encode_image(uploaded_img)

    with tab2:
        st.info("T·∫£i file code/text ƒë·ªÉ AI ƒë·ªçc hi·ªÉu (T·ªëi ƒëa 2MB)")
        uploaded_txt = st.file_uploader("Ch·ªçn file (.txt, .py, .md, .json):", type=["txt", "py", "md", "json", "csv"])
        file_context = ""
        if uploaded_txt:
            file_context = read_text_file(uploaded_txt)
            with st.expander("Xem n·ªôi dung file ƒë√£ ƒë·ªçc"):
                st.code(file_context)

    # N√∫t Action (ƒê·∫∑t ·ªü ngo√†i tab ƒë·ªÉ lu√¥n b·∫•m ƒë∆∞·ª£c)
    st.markdown("---")
    btn_submit = st.button("üöÄ K√çCH HO·∫†T TITAN", use_container_width=True)

# --- OUTPUT AREA ---
with col_right:
    st.subheader("üíé K·∫øt qu·∫£")
    
    if btn_submit:
        if not api_key:
            st.error("‚ö†Ô∏è CH∆ØA C√ì CH√åA KH√ìA: Vui l√≤ng nh·∫≠p API Key ·ªü menu b√™n tr√°i!")
        elif not user_text and not processed_img_data and not file_context:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p n·ªôi dung ho·∫∑c t·∫£i ·∫£nh/file!")
        else:
            with st.spinner("‚è≥ TITAN ƒëang suy nghƒ©..."):
                # Gh√©p Context t·ª´ file v√†o Prompt
                full_prompt = user_text
                if file_context:
                    full_prompt = f"CONTEXT DATA:\n{file_context}\n\n---\nQUESTION:\n{user_text}"
                
                # G·ªçi h√†m x·ª≠ l√Ω
                result = call_gemini_rest_api(
                    api_key=api_key,
                    model=selected_model,
                    prompt=full_prompt,
                    image_data=processed_img_data,
                    system_instruction=current_instruction
                )
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                if result["success"]:
                    st.success("‚úÖ Ho√†n t·∫•t!")
                    st.markdown(result["text"])
                    
                    # N√∫t Copy/Download
                    st.download_button(
                        label="üíæ T·∫£i k·∫øt qu·∫£ (.md)",
                        data=result["text"],
                        file_name="titan_output.md",
                        mime="text/markdown"
                    )
                else:
                    st.error("üî• C√ì L·ªñI X·∫¢Y RA!")
                    st.json(result) # Hi·ªÉn th·ªã chi ti·∫øt l·ªói JSON ƒë·ªÉ debug
